bundle:
  name: databricks_cicd_bundle
  description: Unified CI/CD Bundle for Dev, UAT, and Prod
  version: 1.0.0

# =========================================================
# Global workspace definition
# =========================================================
workspace:
  root_path: /Workspace/main/databricks_cicd/${bundle.environment}

# =========================================================
# File sync settings (exclude non-deploy files)
# =========================================================
files:
  include:
    - Notebooks/**
    - dlt/**
  exclude:
    - .github/**
    - bundle_config/**
    - .git/**
    - tests/**
    - docs/**
    - **/__pycache__/**
    - **/*.pyc
    - README.md
    - LICENSE

# =========================================================
# Dummy artifact definition (required for schema compliance)
# =========================================================
artifacts:
  default:
    files:
      - path: .

# =========================================================
# Environment-specific configurations
# =========================================================
environments:

  dev:
    default: true
    workspace:
      root_path: /Workspace/main/databricks_cicd/dev
    resources:
      jobs:
        main_job:
          name: "Main Job (Dev)"
          job_clusters:
            - job_cluster_key: dev_cluster
              new_cluster:
                spark_version: 14.3.x-scala2.12
                node_type_id: Standard_D3_v2
                num_workers: 2
          tasks:
            - task_key: notebook_task
              description: "Execute Dev test notebook"
              notebook_task:
                notebook_path: /Workspace/main/databricks_cicd/dev/Notebooks/testNotebook
              job_cluster_key: dev_cluster

      pipelines:
        dlt_pipeline:
          name: "DLT Pipeline (Dev)"
          development: true
          continuous: true
          clusters:
            - label: default
              num_workers: 2
          libraries:
            - notebook:
                path: /Workspace/main/databricks_cicd/dev/dlt/pipeline_notebook

  uat:
    workspace:
      root_path: /Workspace/main/databricks_cicd/uat
    resources:
      jobs:
        main_job:
          name: "Main Job (UAT)"
          job_clusters:
            - job_cluster_key: uat_cluster
              new_cluster:
                spark_version: 14.3.x-scala2.12
                node_type_id: Standard_D3_v2
                num_workers: 2
          tasks:
            - task_key: notebook_task
              description: "Run all notebooks in UAT"
              notebook_task:
                notebook_path: /Workspace/main/databricks_cicd/uat/Notebooks/testNotebook
              job_cluster_key: uat_cluster

      pipelines:
        dlt_pipeline:
          name: "DLT Pipeline (UAT)"
          development: false
          continuous: true
